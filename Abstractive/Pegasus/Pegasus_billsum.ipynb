{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNKG4QevavMa"
   },
   "outputs": [],
   "source": [
    "!pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio===0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-OBrGewb_Wu",
    "outputId": "fa9ba9a6-f53b-4adf-db7e-88afe5d16dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\arnav\\lib\\site-packages (4.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\arnav\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\arnav\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\arnav\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\arnav\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\arnav\\lib\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\arnav\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arnav\\lib\\site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\arnav\\lib\\site-packages (from transformers) (1.22.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\arnav\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arnav\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arnav\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\arnav\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\arnav\\lib\\site-packages (from requests->transformers) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arnav\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arnav\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arnav\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1E_ZZrBGe4MI",
    "outputId": "5c8fc065-2735-48bd-eabd-a2dbae4280ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\arnav\\lib\\site-packages (0.1.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments,pipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERL_fIRDcBOB",
    "outputId": "1f76847c-c0ec-43ad-e3a6-d822f734f83a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"../Dataset/all_v1_transpose.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df = df[['original_text','reference_summary']]\n",
    "df.rename(columns = {'original_text':'source', 'reference_summary':'target'}, inplace = True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RnCjv6n7wVrN"
   },
   "outputs": [],
   "source": [
    "X = df['source']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K35erKW3cINP",
    "outputId": "31c90613-add1-4cd0-9046-3775a2a8ce13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome to the pokémon go video game services ...</td>\n",
       "      <td>hi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>by using our services you are agreeing to thes...</td>\n",
       "      <td>by playing this game you agree to these terms....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you want to use certain features of the ser...</td>\n",
       "      <td>you have to use google pokemon trainer club or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>during game play please be aware of your surro...</td>\n",
       "      <td>don t die or hurt others and if you do it s no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject to your compliance with these terms ni...</td>\n",
       "      <td>don t copy modify resell distribute or reverse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  welcome to the pokémon go video game services ...   \n",
       "1  by using our services you are agreeing to thes...   \n",
       "2  if you want to use certain features of the ser...   \n",
       "3  during game play please be aware of your surro...   \n",
       "4  subject to your compliance with these terms ni...   \n",
       "\n",
       "                                              target  \n",
       "0                                                hi.  \n",
       "1  by playing this game you agree to these terms....  \n",
       "2  you have to use google pokemon trainer club or...  \n",
       "3  don t die or hurt others and if you do it s no...  \n",
       "4  don t copy modify resell distribute or reverse...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YuCMAtjGeM86"
   },
   "outputs": [],
   "source": [
    "class PegasusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NOdzySbseTAg"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_11472/907735040.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Arnav\\AppData\\Local\\Temp/ipykernel_11472/907735040.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    tokenizer = AutoTokenizer.from_pretrained(model_name)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(model_name, train_texts, train_labels, test_texts, test_labels):\n",
    "    \"\"\"\n",
    "    Prepare input data for model fine-tuning\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    prepare_test = False if test_texts is None or test_labels is None else True\n",
    "\n",
    "    def tokenize_data(texts, labels):\n",
    "        encodings = tokenizer(texts, truncation=True, padding=True, max_length = 600)\n",
    "        decodings = tokenizer(labels, truncation=True, padding=True, max_length = 256)\n",
    "        dataset_tokenized = PegasusDataset(encodings, decodings)\n",
    "        return dataset_tokenized\n",
    "\n",
    "    train_dataset = tokenize_data(train_texts, train_labels)\n",
    "    test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
    "\n",
    "    return train_dataset, test_dataset, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sFuuoDheVvr"
   },
   "outputs": [],
   "source": [
    "def prepare_fine_tuning(model_name, tokenizer, train_dataset, test_dataset, freeze_encoder=False, output_dir='./results'):\n",
    "    \"\"\"\n",
    "    Prepare configurations and base model for fine-tuning\n",
    "    \"\"\"\n",
    "    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=output_dir,           # output directory\n",
    "      num_train_epochs=3,              # total number of training epochs\n",
    "      per_device_train_batch_size=1,   # batch size per device during training, can increase if memory allows\n",
    "      per_device_eval_batch_size=1,    # batch size for evaluation, can increase if memory allows\n",
    "      save_steps=500,                  # number of updates steps before checkpoint saves\n",
    "      save_total_limit=5,              # limit the total amount of checkpoints and deletes the older checkpoints\n",
    "      evaluation_strategy='steps',     # evaluation strategy to adopt during training\n",
    "      eval_steps=100,                  # number of update steps before evaluation\n",
    "      warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "      weight_decay=0.01,               # strength of weight decay\n",
    "      logging_dir='./logs',            # directory for storing logs\n",
    "      logging_steps=100,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "      model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "      args=training_args,                  # training arguments, defined above\n",
    "      train_dataset=train_dataset,         # training dataset\n",
    "      eval_dataset=test_dataset,           # evaluation dataset\n",
    "      tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAJgXHGtsfMy"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Qs6bhoOz8uV"
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = list(X_train), list(y_train)\n",
    "test_texts, test_labels = list(X_test), list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "PBpl_Dzoebmd",
    "outputId": "067a50a9-1e83-4530-8d98-3d4e677148eb"
   },
   "outputs": [],
   "source": [
    "model_name = 'google/pegasus-billsum'\n",
    "train_dataset,test_dataset, tokenizer = prepare_data(model_name, train_texts, train_labels,test_texts,test_labels)\n",
    "trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset,test_dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlT-HJrKefPH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('./ouput_billsum/'):\n",
    "    os.makedirs('./ouput_billsum/')\n",
    "trainer.model.save_pretrained(\"./ouput_billsum/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owF3ABCdtHRK",
    "outputId": "ad51566c-edc8-482d-b25c-b625b04c1841"
   },
   "outputs": [],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9qaEYjEuYgu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline,AutoModelForSeq2SeqLM, AutoTokenizer, PreTrainedTokenizer, PegasusTokenizer, PegasusForConditionalGeneration, PretrainedConfig\n",
    "import pandas as pd\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlKarDPFujTP"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLjUSKWyuoRZ"
   },
   "outputs": [],
   "source": [
    "config = PretrainedConfig.from_json_file('ouput_billsum/config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16bRnBoQurSD"
   },
   "outputs": [],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\"ouput_billsum\", config = config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjDioGUmu736"
   },
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "  input_tokenized = tokenizer.encode(text, return_tensors='pt',max_length=600,truncation=True).to(device)\n",
    "  summary_ids = model.generate(input_tokenized,\n",
    "                                  num_beams=9,\n",
    "                                  no_repeat_ngram_size=3,\n",
    "                                  length_penalty=2.0,\n",
    "                                  min_length=50,\n",
    "                                  max_length=150,\n",
    "                                  early_stopping=True)\n",
    "  summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
    "\n",
    "  return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yssn6UgDvQtk"
   },
   "outputs": [],
   "source": [
    "y_pred = X_test.apply(lambda x: summarize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EAFs6ZhvclM"
   },
   "outputs": [],
   "source": [
    "summary = pd.concat([y_test.to_frame(name=\"reference_summary\"), y_pred.to_frame(name=\"generated_summary\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWfwQnCUvfjT"
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCG0tY_VvpUn",
    "outputId": "f2e043d0-2a01-46a8-ffcb-3db66354c740"
   },
   "outputs": [],
   "source": [
    "rouge.get_scores(summary['generated_summary'], summary['reference_summary'],avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qONp1QL4vqib"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPsKdLzsZrqIQvvyLC6KuEC",
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
